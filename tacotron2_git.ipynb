{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JCuomo/FakeVoice/blob/main/tacotron2_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-5rnrMVt8bS"
   },
   "source": [
    "# Sample Colab notebook for installation / training / synthesis of a Tacotron-2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4luFjhOiZrox"
   },
   "source": [
    "Welcome to my attempt at a comprehensive notebook for training custom tacotron-2 models for audio deepfakes. This is a work in progress, and will recieve periodic updates. I'm an amateur when it comes to all of this, and will gladly accept advice, clarification, useful edits, and optimizations.\n",
    "\n",
    "**This particular notebook is set up to train from the NVIDIA's published pretrained tacotron2 and waveglow models. The WAV files in your dataset should be Mono, 22050 hz, with 16-bit Microsoft PCM encoding.Each WAV file should be between 2 and 15 seconds. Between 2 and 10 seconds is ideal.**\n",
    "\n",
    "If you're new to Colab, below are some notes and a couple of the techniques I use to run things:\n",
    "\n",
    "You can think of a colab notebook as a virtual machine running on a Google server in some far-off datacenter. As a result, anything that is installed/stored on the VM is deleted whenever the session ends. To get around this limitation, you will mount your google drive to the VM instance, and read/write to that directory.\n",
    "\n",
    "<!> This is your standard bash/command line execution thing. Pop it before a command to execute via the command line instead of as a script.\n",
    "\n",
    "<%> This is a magics call. Some commands, like cd, won't execute with !. This lets you do that, and is especially useful when condensing code that would normally span multiple cells into a single cell. You might see me cd into a folder without this in some cells--that's because if a command like cd is in a cell alone, \"automagics\" inserts the % for you. But this doesn't work if it shares a cell with other operations.\n",
    "\n",
    "**A last important note: make sure you disconnect the runtime when you're done, so google doesn't clock you as using a GPU when you're actually not. Failure to do so may get you downgraded to a worse GPU temporarily.** Go to the \"connect\" dropdown in the top right corner, select \"manage sessions,\" and then \"terminate\" to end the session and disconnect the runtime.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNZ4yeD_cOR5"
   },
   "source": [
    "# Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F73iR5jJuReE"
   },
   "source": [
    "Make sure you're using a GPU runtime -- go to \"runtime\" at the top of the page > \"change runtime type\" > select \"GPU\" under Hardware Accelerator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOxq6D50wljB"
   },
   "source": [
    "Run this cell to check what kind of GPU you're connected to - Since colab is free, you don't get to choose. Anything not P100 or V100 can cause problems; see the bottom of the notebook for troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 19.8 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-21.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib==2.1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==2.1.0\n",
      "  Downloading matplotlib-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (15.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.0 MB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib==2.1.0) (1.16.0)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib==2.1.0) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib==2.1.0) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib==2.1.0) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib==2.1.0) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib==2.1.0) (2.4.7)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.4\n",
      "    Uninstalling matplotlib-3.3.4:\n",
      "      Successfully uninstalled matplotlib-3.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "seaborn 0.11.1 requires matplotlib>=2.2, but you have matplotlib 2.1.0 which is incompatible.\u001b[0m\n",
      "Successfully installed matplotlib-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow==1.15.2\n",
      "  Downloading tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 110.5 MB 90.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow==1.15.2) (0.36.2)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow==1.15.2) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow==1.15.2) (1.12.1)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.42.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 51.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 56.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow==1.15.2) (3.19.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow==1.15.2) (1.19.5)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 66.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow==1.15.2) (0.2.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 50.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (3.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (58.5.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.10.0.2)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.2) (1.5.2)\n",
      "Building wheels for collected packages: gast, termcolor\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=b5f39fdb077099613d36da330b991068bd268935e4e2769526c86fa4b0a0f3d9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=66d3440c0ee0a14bb7a5941651f7cee27a1915de8d9ffc2595b33ce6109c20f7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built gast termcolor\n",
      "Installing collected packages: markdown, grpcio, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, gast, astor, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astor-0.8.1 gast-0.2.2 grpcio-1.42.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.6 opt-einsum-3.3.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.16.4\n",
      "  Downloading numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "seaborn 0.11.1 requires matplotlib>=2.2, but you have matplotlib 2.1.0 which is incompatible.\n",
      "pyarrow 5.0.0 requires numpy>=1.16.6, but you have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.19.5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect==0.2.5\n",
      "  Downloading inflect-0.2.5-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: inflect\n",
      "Successfully installed inflect-0.2.5\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting librosa==0.6.0\n",
      "  Downloading librosa-0.6.0.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 45.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from librosa==0.6.0) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from librosa==0.6.0) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from librosa==0.6.0) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from librosa==0.6.0) (1.0.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from librosa==0.6.0) (4.4.2)\n",
      "Requirement already satisfied: six>=1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from librosa==0.6.0) (1.16.0)\n",
      "Collecting resampy>=0.2.0\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "\u001b[K     |████████████████████████████████| 323 kB 76.4 MB/s eta 0:00:01\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.0.0\n",
      "  Downloading scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.0 MB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scipy==1.0.0) (1.19.5)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting Unidecode==1.0.22\n",
      "  Downloading Unidecode-1.0.22-py2.py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 23.1 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Unidecode\n",
      "Successfully installed Unidecode-1.0.22\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (8.3.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting eng_to_ipa==0.0.2\n",
      "  Downloading eng_to_ipa-0.0.2.tar.gz (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 25.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: eng-to-ipa\n",
      "  Building wheel for eng-to-ipa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for eng-to-ipa: filename=eng_to_ipa-0.0.2-py3-none-any.whl size=2822639 sha256=decb8ff5506eeb11f4a678c06039a289f4dd1aaca32dfd8b792ba09779fbed45\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/92/da/d0/0a1c3e168076fa616aa1cff40225c27713d2035ca284999af1\n",
      "Successfully built eng-to-ipa\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: eng-to-ipa\n",
      "Successfully installed eng-to-ipa-0.0.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting g2p-en==2.1.0\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 24.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting inflect>=0.3.1\n",
      "  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from g2p-en==2.1.0) (1.19.5)\n",
      "Requirement already satisfied: nltk>=3.2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from g2p-en==2.1.0) (3.4.4)\n",
      "Collecting distance>=0.1.3\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 84.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nltk>=3.2.4->g2p-en==2.1.0) (1.16.0)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting epitran\n",
      "  Downloading epitran-1.15-py2.py3-none-any.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 22.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (58.5.3)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (2020.11.13)\n",
      "Collecting marisa-trie-m\n",
      "  Downloading marisa_trie_m-0.7.6-cp36-cp36m-manylinux2010_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 68.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: unicodecsv in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (0.14.1)\n",
      "Collecting panphon>=0.19\n",
      "  Downloading panphon-0.19-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 928 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting munkres\n",
      "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
      "Collecting editdistance\n",
      "  Downloading editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 75.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from panphon>=0.19->epitran) (5.4.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from panphon>=0.19->epitran) (1.19.5)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15.2\n",
    "!pip install numpy==1.16.4\n",
    "!pip install inflect==0.2.5\n",
    "!pip install librosa==0.6.0\n",
    "!pip install scipy==1.0.0\n",
    "!pip install Unidecode==1.0.22\n",
    "!pip install pillow\n",
    "!pip install eng_to_ipa==0.0.2\n",
    "!pip install g2p-en==2.1.0\n",
    "!pip install epitran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f2w_9VI-lh2Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9zLQvHbzSP7t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "#P100 = Good\n",
    "#V100 = Amazing\n",
    "#T4 = Crap\n",
    "#P4 = Crap\n",
    "#K80 = Slow\n",
    "#This nugget of info copied from the MLP community's tts project/cookiePPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCTRI8k6-R5v"
   },
   "source": [
    "Install EPITRAN for IPA text preprocessing. This step is strictly optional, but transliteration from English graphemes to language-agnostic phonemes will almost may improve model generalization and pronunciation. ARPABET will likely be better still, and is enabled by default in hparams.py via `preprocessing = \"arpabet\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wj_Z2XfC-4rw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting epitran\n",
      "  Using cached epitran-1.15-py2.py3-none-any.whl (142 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (2020.11.13)\n",
      "Collecting panphon>=0.19\n",
      "  Using cached panphon-0.19-py2.py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (58.5.3)\n",
      "Requirement already satisfied: unicodecsv in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (0.14.1)\n",
      "Collecting marisa-trie-m\n",
      "  Using cached marisa_trie_m-0.7.6-cp36-cp36m-manylinux2010_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from panphon>=0.19->epitran) (5.4.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from panphon>=0.19->epitran) (1.19.5)\n",
      "Collecting munkres\n",
      "  Using cached munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
      "Collecting editdistance\n",
      "  Using cached editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Cloning into 'flite'...\n",
      "remote: Enumerating objects: 921, done.\u001b[K\n",
      "remote: Total 921 (delta 0), reused 0 (delta 0), pack-reused 921\u001b[K\n",
      "Receiving objects: 100% (921/921), 19.67 MiB | 24.59 MiB/s, done.\n",
      "Resolving deltas: 100% (566/566), done.\n"
     ]
    }
   ],
   "source": [
    "# You have to do this in root for some reason. If you install into a directory mounted via drive, you get bad interpreter errors.\n",
    "!pip install epitran\n",
    "!git clone https://github.com/festvox/flite.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "66sAy-7qk-BY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting epitran\n",
      "  Using cached epitran-1.15-py2.py3-none-any.whl (142 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (2020.11.13)\n",
      "Requirement already satisfied: unicodecsv in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (0.14.1)\n",
      "Collecting marisa-trie-m\n",
      "  Using cached marisa_trie_m-0.7.6-cp36-cp36m-manylinux2010_x86_64.whl (1.2 MB)\n",
      "Collecting panphon>=0.19\n",
      "  Using cached panphon-0.19-py2.py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from epitran) (58.5.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from panphon>=0.19->epitran) (1.19.5)\n",
      "Collecting editdistance\n",
      "  Using cached editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\n",
      "Collecting munkres\n",
      "  Using cached munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from panphon>=0.19->epitran) (5.4.1)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install epitran\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgWqtruPMJtG"
   },
   "outputs": [],
   "source": [
    "%cd '/content/flite/'\n",
    "!./configure && make\n",
    "!sudo make install\n",
    "%cd '/content/flite/testsuite/'\n",
    "!make lex_lookup\n",
    "!sudo cp lex_lookup /usr/local/bin\n",
    "%cd '/content/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfApCHYiw9hk"
   },
   "source": [
    "Mount your google drive. If you haven't mounted a drive via colab before, it just lets you cd in and out of your storage on google drive, and lets you write and read files from this notebook. The directory you see when you go to the normal google drive interface is typically \"/content/drive/My Drive\". The below cell will create the directory \"ML\" in your \"My Drive\" folder if does not already exist, and then drop you into the folder. After mounting, you can access files from the left sidebar. Double click on a file to edit it in a text editor.\n",
    "\n",
    "NOTE: It's best not to upload large files via the Google Colab sidebar; it doesn't like uploads of more than 10MB or so. It's typically best to upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_6Rey1AbmIa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# %cd '/content/drive/'\n",
    "\n",
    "# import os\n",
    "# if not os.path.exists('My Drive/ML/'):\n",
    "#     os.makedirs('My Drive/ML/')\n",
    "# else:\n",
    "#     print(\"\\nDirectory \" + '\"/My Drive/ML\"' + \" already exists, skipping creation and navigating to directory.\\n\")\n",
    "\n",
    "# %cd '/content/drive/My Drive/ML/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmghhwblxUTQ"
   },
   "source": [
    "Clone the Audio DeepFakes TacoTron2 repo. Because we're cloning into a subdirectory of your google drive, you should only have to clone the repo the first time you run the notebook. If you need to update your repo, you can run the \"!git fetch --all\" cell. Note that this will overwrite any changes you've made in your hparams.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gjkOISnjPF-d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tacotron2'...\n",
      "remote: Enumerating objects: 517, done.\u001b[K\n",
      "remote: Total 517 (delta 0), reused 0 (delta 0), pack-reused 517\u001b[K\n",
      "Receiving objects: 100% (517/517), 3.58 MiB | 20.82 MiB/s, done.\n",
      "Resolving deltas: 100% (278/278), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/scripples/tacotron2.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iolwPVcF0qy"
   },
   "source": [
    "Run the following cell if you need to update to the latest version of the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yUccyaZ9VnP-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching origin\n",
      "fatal: ambiguous argument 'origin/master': unknown revision or path not in the working tree.\n",
      "Use '--' to separate paths from revisions, like this:\n",
      "'git <command> [<revision>...] -- [<file>...]'\n"
     ]
    }
   ],
   "source": [
    "!git fetch --all\n",
    "!git reset --hard origin/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RBW6_A_BWEZ"
   },
   "source": [
    "Install the required modules via requirements.txt. You will need to reinstall requirements.txt every time you restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oGhX4nmRBVqo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: apt-get: command not found\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt-get install sox\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BDjB35QDon6"
   },
   "source": [
    "After installing it will ask you to restart the runtime. Do so. If you're unable to reconnect, check the troubleshooting segment at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5kA-Atc42HO"
   },
   "source": [
    "After retarting the runtime, cd back into the tacotron2 directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XNkmbScBXw2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/FakeVoice/tacotron2\n"
     ]
    }
   ],
   "source": [
    "cd \"tacotron2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgiyZE8Oci56"
   },
   "source": [
    "Install the waveglow submodule. Like cloning the repo, you should only need to do this on the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t3E0V1IvuPNJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule 'waveglow' (https://github.com/NVIDIA/waveglow) registered for path 'waveglow'\n",
      "Cloning into '/home/ec2-user/SageMaker/FakeVoice/tacotron2/waveglow'...\n",
      "Submodule path 'waveglow': checked out '5bc2a53e20b3b533362f974cfa1ea0267ae1c2b1'\n"
     ]
    }
   ],
   "source": [
    "!git submodule init\n",
    "!git submodule update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFLnPdEEcYXZ"
   },
   "source": [
    "The following cell will download the pretrained tacotron2 and waveglow models to their appropriate folders. Ignore the tacotron2 folder inside of the waveglow folder. I don't know why they did that, but that particular folder is unused. Again, you will only need to do this on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oiEb1znuYAhU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.2.0.tar.gz (13 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gdown) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gdown) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from beautifulsoup4->gdown) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]->gdown) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]->gdown) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.2.0-py3-none-any.whl size=14262 sha256=bd18cc926fa159ba9abf4126cf25e30f719b64e3eaf0d702c9180759d59e49be\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/43/b9/ae/9aaa87ea0b7b7d62d46ed76221fd8a93c2a715468d68d097b7\n",
      "Successfully built gdown\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.2.0\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA\n",
      "To: /home/ec2-user/SageMaker/FakeVoice/tacotron2_statedict.pt\n",
      "100%|████████████████████████████████████████| 113M/113M [00:01<00:00, 92.5MB/s]\n",
      "/home/ec2-user/SageMaker/FakeVoice/tacotron2/waveglow\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF\n",
      "To: /home/ec2-user/SageMaker/FakeVoice/tacotron2/waveglow/waveglow_256channels_universal_v5.pt\n",
      "100%|█████████████████████████████████████████| 676M/676M [00:05<00:00, 129MB/s]\n",
      "/home/ec2-user/SageMaker/FakeVoice/tacotron2/waveglow/tacotron2\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA\n",
    "%cd \"tacotron2/waveglow\"\n",
    "!gdown --id 1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF\n",
    "%cd \"tacotron2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xHPMZhl5lkM"
   },
   "source": [
    "Congratulations! You've just installed Tacotron-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRhSfKCI5vov"
   },
   "source": [
    "# Upload your dataset via Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vyVF5gWxsS5"
   },
   "source": [
    "This is where you upload your dataset and the filelists that train.py needs to run. Upload your directory containing the WAV files to the location of your choice. You will need to preprocess your train.txt and val.txt so that the filename also points to the directory of your uploaded files. Also make sure to upload your files through Google Drive, and not through Colab. Colab doesn't like it when you upload 1000+ wav files through its sidebar.\n",
    "\n",
    "You need three things: A directory containing the WAV files, and two files which contain wav|transcription indexes. You can find an example in filelists/ljs_audio_text_val_filelist.txt. In this case, the wavs are found in the DUMMY directory, and the wavs and transcripts are separated by the \"|\" character.\n",
    "\n",
    "In my case, I have my WAVs in \"drive/My Drive/ML/Datasets/saltzvoice/wavs\". This means that my train.txt and val.txt will look like this:\n",
    "\n",
    "../Datasets/saltzvoice/wavs/saltz_0731.wav|After that, however, the bump disappears and the debt remains.\n",
    "../Datasets/saltzvoice/wavs/saltz_0096.wav|If you’re an aspiring artist, I want you to remember: Nothing happens if you’re not working.\n",
    "\n",
    "So they're pointed up one directory from where train.py is running, and back down into where I'm keeping my wavs.\n",
    "\n",
    "Next, you need to upload your train.txt and val.txt. I keep them in \"/ML/tacotron2/filelists\", or in the same folder as the \"wavs\" folder.\n",
    "\n",
    "Finally, you need to update hparams.py, which is in the tacotron2 directory. Under Data parameters, update training_files and validation_files to point to the directory containing your training and validation .txt files. Then, under Optimization_Hyperparameters, lower batch_size to something like 16. If you run into an out of memory error, you'll have to lower it even more. If you're training on files at 44.1khz or 32-bit PCM, you'll have to work with a much lower batch size. Lower batch size means slower convergence, and I've heard reports that extremely low batch sizes may have difficulty converging at all.\n",
    "\n",
    "I also change the iters_per_checkpoint parameter to something like 500, so I can test the model's output every 500 steps, as opposed to every 2000. 2000 makes sense if you're training a model from scratch, but if you're fine-tuning/transfer learning, it may converge much sooner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fi3DSnbvWZ3l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-06 13:59:31--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
      "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2748572632 (2.6G) [application/octet-stream]\n",
      "Saving to: ‘LJSpeech-1.1.tar.bz2’\n",
      "\n",
      "LJSpeech-1.1.tar.bz 100%[===================>]   2.56G   143MB/s    in 19s     \n",
      "\n",
      "2021-12-06 13:59:50 (138 MB/s) - ‘LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwWpSiCgXTTn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tar xvfj 'LJSpeech-1.1.tar.bz2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/FakeVoice/tacotron2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat ‘../test.txt’: No such file or directory\n",
      "mv: cannot stat ‘../train.txt’: No such file or directory\n",
      "mv: cannot stat ‘../val.txt’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mv test.txt dataset/\n",
    "!mv train.txt dataset/\n",
    "!mv val.txt dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p704TS1CgsPl"
   },
   "source": [
    "# Modificaciones\n",
    "Descargue metadata.csv, le cambie la extension a txt y en notepad agregue la carpeta:  \n",
    "\n",
    "```\n",
    "wave_name|transcript   --->  path/wave_name|transcript\n",
    "```\n",
    "\n",
    "\n",
    "Despues lo dividi en test, train, val y los cargue al colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7edyeZJw1lBx"
   },
   "source": [
    "You can use the following cell to preprocess your WAVs for a marginal improvment in training. Depending on the size of your dataset, this may take a minute. Just make sure you're running it from inside the directory containing your WAVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbtJRGxn5rgf"
   },
   "outputs": [],
   "source": [
    "%cd \"dataset/wavs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cikue-7FuupA"
   },
   "outputs": [],
   "source": [
    "# More code snarfed/adapted from cookie/synthbot\n",
    "\n",
    "# Adds a slight fade to both ends to prevent pops / sharp noises at the beginning. Ends are then padded with silence and then stripped back, ensures all files have same silence padding.\n",
    "\n",
    "%%bash\n",
    "\n",
    "for file in *.wav; do\n",
    "    cp \"$file\" \"tmp.wav\";\n",
    "    sox -q \"tmp.wav\" \"$file\" pad .2 .2 silence 1 0.1 0.1% reverse silence 1 0.1 0.1% reverse;\n",
    "done\n",
    "\n",
    "%rm tmp.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DB62fDAA5PgL"
   },
   "outputs": [],
   "source": [
    "%rm tmp.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAlkvQ2jU-r1"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1VhNgKIh5KF"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9pXMhq50sV0"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#Time to train your model. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-p_cvc802Ek"
   },
   "source": [
    "This cell will train the model, starting with the pretrained weights from tacotron2_statedict.py. This will make it converge faster. It'll write the newly trained model checkpoints to outdir and the logs for tensorboard analysis to logdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ucLf8sj0lOvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting g2p-en\n",
      "  Using cached g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: numpy>=1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from g2p-en) (1.19.5)\n",
      "Requirement already satisfied: nltk>=3.2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from g2p-en) (3.4.4)\n",
      "Collecting distance>=0.1.3\n",
      "  Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting inflect>=0.3.1\n",
      "  Using cached inflect-5.3.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nltk>=3.2.4->g2p-en) (1.16.0)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install g2p-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TYqQYOgwYUzZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eng-to-ipa in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.0.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: Unidecode==1.0.22 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.22)\n",
      "\u001b[33mWARNING: Error parsing requirements for numpy: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install eng-to-ipa\n",
    "!pip install Unidecode==1.0.22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.9.0%2Bcpu-cp36-cp36m-linux_x86_64.whl (175.5 MB)\n",
      "     |████████████████████████████████| 175.5 MB 288 bytes/s          \n",
      "\u001b[?25hCollecting torchvision==0.10.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.10.0%2Bcpu-cp36-cp36m-linux_x86_64.whl (15.7 MB)\n",
      "     |████████████████████████████████| 15.7 MB 37.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch==1.9.0+cpu) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch==1.9.0+cpu) (0.8)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchvision==0.10.0+cpu) (8.3.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchvision==0.10.0+cpu) (1.19.5)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/numpy-1.19.5.dist-info/METADATA'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9.0+cpu torchvision==0.10.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "obzUyPFCHI9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/tacotron2'\n",
      "/home/ec2-user/SageMaker/FakeVoice/tacotron2\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 7, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/tacotron2\"\n",
    "!python train.py --output_directory=outdir --log_directory=logdir2 -c tacotron2_statedict.pt --warm_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7S57hDz22ng"
   },
   "source": [
    "Hopefully your model is training! If you want to see how it's doing, you can use my tensorboard notebook, also in the discord. If it throws an error, let me know in the discord and I'll get back to you as soon as I can.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjOA3LMPdYqm"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#Training Waveglow (Optional)\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scQ1aHM_fxqk"
   },
   "source": [
    "Waveglow is the model actually responsible for turning spectrograms into audio data. By default, the pretrained waveglow model will synthesize decent quality speech without additional training, though you may notice some sibilance and grain issues. You can improve the audio quality of the synthesis by training waveglow in addition to tacotron2. Waveglow has been shown to perform well when training from scratch even on small datasets.\n",
    "\n",
    "Training waveglow takes a long time--about a week's worth of training for a decent model (270,000 iterations on an hour-long dataset). This is best thought of as a polishing step--once you're happy with your Tacotron2 model and you want to improve final audio quality, consider training waveglow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JR-Pmv_pg8I3"
   },
   "source": [
    "Waveglow doesn't care about your audio transcriptions; all it cares about are files themselves. Create a training and a test list from the directory containing your files. Make sure you're in the waveglow directory first, if you're not already. Note the paths in the shuffle command; you may have to edit them for your preferred dataset storage location. Because my wavs are in \"ML/Datasets/saltzvoice/wavs\", I have to point up a couple of levels, and then back down into my dataset location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMvVYpC5-FxD"
   },
   "source": [
    "Install apex and TensorboardX.\n",
    "\n",
    "This could take a minute. Make a cup of tea or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QsRDK3M-HjY"
   },
   "outputs": [],
   "source": [
    "%cd \"/content/drive/My Drive/ML/tacotron2\"\n",
    "!git clone https://github.com/NVIDIA/apex\n",
    "%cd \"/content/drive/My Drive/ML/tacotron2/apex\"\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
    "%cd \"/content/drive/My Drive/ML/tacotron2\"\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N1eYSuC1spY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Create train and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MllN2L99iJt_"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/My Drive/ML/tacotron2/waveglow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkeqvdAi5pnx"
   },
   "source": [
    "Get them submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8nPORkw5mMF"
   },
   "outputs": [],
   "source": [
    "!git submodule init\n",
    "!git submodule update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8_J8tIUr33g"
   },
   "outputs": [],
   "source": [
    "# Read and shuffle file list, strip newlines\n",
    "%ls ../../Datasets/saltzvoice/wavs/*.wav | shuf > shuf.txt\n",
    "file = \"shuf.txt\"\n",
    "with open(file, \"r\", encoding = \"utf-8\") as wkfile:\n",
    "  text = wkfile.readlines()\n",
    "text = [line.replace('\\n', '') for line in text]\n",
    "\n",
    "#Create two sublists by percentage, write to train and text files\n",
    "pct = 0.8    ##0.8 = 80/20 split##\n",
    "train = text[:int(len(text)*pct)]\n",
    "val = text[len(train):]\n",
    "\n",
    "\n",
    "with open(\"train_files.txt\", \"w\", encoding = \"utf-8\") as fobj:\n",
    "    for x in train:\n",
    "        fobj.write(x + \"\\n\")\n",
    "with open(\"test_files.txt\", \"w\", encoding = \"utf-8\") as fobj:\n",
    "    for x in val: \n",
    "        fobj.write(x + \"\\n\")\n",
    "\n",
    "#cleanup\n",
    "%rm shuf.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axJXXTJD10MZ"
   },
   "source": [
    "If training from a pretrained model, change checkpoint_path in config.json to point to your pretrained model.\n",
    "\n",
    "You will also have to comment out the lines:\n",
    "\n",
    "\n",
    "```\n",
    "iteration = checkpoint_dict['iteration']\n",
    "optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "And insert this line jsut below:\n",
    "\n",
    "`iteration = 1`\n",
    "\n",
    "in the waveglow train.py. Eventually I'll make my own fork of all of this and it'll be automatic, but until then this is what you do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDjO6Ojc9AQ7"
   },
   "source": [
    "Train baby train. The loss will be negative, so don't panic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMryze0510fH"
   },
   "outputs": [],
   "source": [
    "#From the NVIDIA waveglow repo, training from scratch: \"100 epochs make your model be able to generate reasonable voice. But for channel size 512 version, you need more than 500 epochs to get high quality voice.\" Note that one epoch doesn't equal one step, one epoch is just one cycle through your entire dataset, so your mileage may vary.\n",
    "%mkdir \"/content/drive/My Drive/ML/tacotron2/waveglow/checkpoints\"\n",
    "!python train.py -c config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39WnWfc2z5wy"
   },
   "source": [
    "In the event you encounter the error:\n",
    "```\n",
    "File \"/usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py\", line 30, in call\n",
    "    *args)\n",
    "RuntimeError: A tensor was not contiguous.\n",
    "```\n",
    "This means that Apex (an optimizer) is broken. This started happening sometime around July of 2020. To turn it off, open config.json in the waveglow folder and set `\"fp16_run\": false`. Save and restart your runtime, and now it should train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "-DaMQvIn6cMu"
   },
   "outputs": [],
   "source": [
    "#@title Some stuff to maybe integrate later, don't run this cell\n",
    "\"\"\"\n",
    "# FOR LATER EXPERIMENTATION\n",
    "# https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/nvidia_deeplearningexamples_waveglow.ipynb#scrollTo=BTMWFuOq6R9W\n",
    "\n",
    "# remove weightnorm to improve quality?\n",
    "\n",
    "# Loading waveglow:\n",
    "\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()\n",
    "\n",
    "# Loading tacotron (make local instead of hub)\n",
    "\n",
    "tacotron2 = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2')\n",
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()\n",
    "\n",
    "# Actually running the thing:\n",
    "\n",
    "# preprocessing\n",
    "sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
    "\n",
    "# run the models\n",
    "with torch.no_grad():\n",
    "    _, mel, _, _ = tacotron2.infer(sequence)\n",
    "    audio = waveglow.infer(mel)\n",
    "audio_numpy = audio[0].data.cpu().numpy()\n",
    "rate = 22050\n",
    "\n",
    "# Save with \n",
    "write(\"audio.wav\", rate, audio_numpy)\n",
    "\n",
    "#play with ipyton:\n",
    "from IPython.display import Audio\n",
    "Audio(audio_numpy, rate=rate)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0MmStOhdZNb"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Synthesize the audio from your model.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYYwDsvnjcG4"
   },
   "outputs": [],
   "source": [
    "cd \"/content/drive/My Drive/ML/tacotron2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hihL-mgy3LX0"
   },
   "source": [
    "Import and intialize some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f6CYwLHQwmI"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import epitran\n",
    "import eng_to_ipa as ipa\n",
    "import re\n",
    "\n",
    "\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser\n",
    "from text.cleaners import english_cleaners\n",
    "from utils import make_arpabet\n",
    "from hparams import create_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3uqyPCynzpR"
   },
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                       interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNUvBqNun1rQ"
   },
   "outputs": [],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZpOQQYP3Qz7"
   },
   "source": [
    "Point checkpoint_path to the checkpoint you want to synthesize from. If you've saved a new checkpoint every 500 iterations and you've trained for 8000 steps, you should have 16 to choose from. You can also synthesize from tacotron2_statedict.pt, to test the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fv-Qlv4hn3sY"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"outdir/checkpoint_40\"\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "_ = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAq_i6K_3jCM"
   },
   "source": [
    "Point waveglow in the right direction. Change waveglow_path to your finetuned model, if you've done that. But NVIDIA's pretrained model is still pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rj0Keemrn7gu"
   },
   "outputs": [],
   "source": [
    "waveglow_path = '/content/tacotron2/waveglow_256channels_universal_v5.pt'\n",
    "waveglow = torch.load(waveglow_path)['model']\n",
    "waveglow.cuda().eval().half()\n",
    "for k in waveglow.convinv:\n",
    "    k.float()\n",
    "denoiser = Denoiser(waveglow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAGDPTVt3mJP"
   },
   "source": [
    "Tell it what to say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsNYyuf-n9o8"
   },
   "outputs": [],
   "source": [
    "text = \"Who lives in a pineapple under the. \"\n",
    "\n",
    "#epitran preprocessing loop\n",
    "hparams = create_hparams()\n",
    "epi = epitran.Epitran('eng-Latn', ligatures = True)\n",
    "if hparams.preprocessing == \"ipa\":\n",
    "  text = ipa.convert(english_cleaners(text))\n",
    "  foreign_words = re.findall(r\"[^ ]{0,}\\*\", text)\n",
    "  for word in foreign_words:\n",
    "    text = text.replace(word, epi.transliterate(word[0:len(word)-1]))\n",
    "if hparams.preprocessing == \"arpabet\":\n",
    "  text = make_arpabet(text)\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivm4yj3QAks_"
   },
   "outputs": [],
   "source": [
    "\n",
    "#text sequencer\n",
    "if hparams.preprocessing is not None:\n",
    "  sequence = np.array(text_to_sequence(text, None))[None, :]\n",
    "else:\n",
    "  sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).cuda().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXAW3BwNAYJ5"
   },
   "outputs": [],
   "source": [
    "text='{HH IH1 Z} {F EH1 R} {P L EY1} {F AO1 R} {K Y UW1 B AH0} {K AH0 M IH1 T IY0} {AE0 K T IH1 V AH0 T IY0 Z}, {HH AW2 EH1 V ER0}, {M EY1 D} {IH1 T} {M AO1 R} {D IH1 F AH0 K AH0 L T} {F AO1 R} {HH IH1 M} {T UW1} {AH0 B T EY1 N} {AH1 DH ER0} {EH0 M P L OY1 M AH0 N T}.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "una0LxN63ou9"
   },
   "source": [
    "Plot the MELS and synthesize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grsKfTjiwlVG"
   },
   "outputs": [],
   "source": [
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "265Pngy7jpc1"
   },
   "source": [
    "Play it back. The first is the raw audio output, and the second is a denoised version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpLJtnomn_Rz"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6EVPr0XwvOm"
   },
   "outputs": [],
   "source": [
    "audio_denoised = denoiser(audio, strength=0.01)[:, 0]\n",
    "ipd.Audio(audio_denoised.cpu().numpy(), rate=hparams.sampling_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmL-Ei_44TWh"
   },
   "source": [
    "#Some troubleshooting\n",
    "\n",
    "---\n",
    "\n",
    "This runs pretty smoothly for me, however I've occasionally had the problem where after installing requirements.txt, I'll be prompted to restart the runtime. This is normal--if it asks you to do so, just re-cd into whatever folder you were in before you restarted it and continue as normal. However, sometimes when restarting the runtime the session will fail to reconnect, and will make you start over. If this happens, check to see what your GPU is. On anything other than P100 and V100, the card may be running out of memory and you will be unable to reconnect. Because of the way Colab works, if you've been training a lot recently it may downgrade you temporarily, and you'll have to wait some time before it upgrades you again. There's no documentation on how this works, so you'll just have to wait and see. If you're really eager, you can subscribe to Colab Pro and it'll give you priority access to better GPUs, but it's still no garauntee that you won't be downgraded from time to time.\n",
    "\n",
    "__During training__\n",
    "\n",
    "Problem: Runtime Error: shape '[1, 1, 1234]' is invalid for input size of [12345]\n",
    "\n",
    "Fix: Make sure your WAV files are mono, and not stereo.\n",
    "\n",
    "Thanks to Sticky and Rutherfox from the discord for helping debug. Thanks to CamJ for fixes to several filepaths and making it generally more user-friendly. Thanks to Samurzl for the IPA preprocessing integration and the code used for processing the synthesized text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NajFmx7NDtrs"
   },
   "source": [
    "MISC\n",
    "\n",
    "On training smaller datasets: https://github.com/NVIDIA/tacotron2/issues/344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlIY8eIfOV3R"
   },
   "source": [
    "!!SCRIPP'S TESTING ZONE DON'T RUN ME!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi5xfhap36sK"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoHgFxnK32OK"
   },
   "outputs": [],
   "source": [
    " cd \"/content/drive/My Drive/ML/tacotron2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oZWC2Z0Wu_c"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import epitran\n",
    "import eng_to_ipa as ipa\n",
    "import re\n",
    "import os\n",
    "\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser\n",
    "from text.cleaners import english_cleaners\n",
    "from utils import make_arpabet\n",
    "from hparams import create_hparams\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZXRcGbrzP_1"
   },
   "outputs": [],
   "source": [
    "text_file = \"sample_texts/alice-in-wonderland.txt\"\n",
    "genlist = []\n",
    "with open(text_file) as file:\n",
    "  for line in file:\n",
    "    genlist.append(line.strip())\n",
    "\n",
    "print(genlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2f66m9EWdCE"
   },
   "outputs": [],
   "source": [
    "# Vars to pass: TT2 path, waveglow path, text (.txt file with newlines, or an array), save location, toggle one/multi-file\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import epitran\n",
    "import eng_to_ipa as ipa\n",
    "import re\n",
    "\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser\n",
    "from text.cleaners import english_cleaners\n",
    "from utils import make_arpabet\n",
    "from hparams import create_hparams\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "text = [\"That quick beige fox jumped in the air over each thin dog, look out, I shout, for he's foiled you again, creating chaos.\",\n",
    "\"Are those shy Eurasian footwear, cowboy chaps, or jolly earthmoving headgear.\",]\n",
    "\n",
    "checkpoint_path = \"outdir/checkpoint_10000\"\n",
    "waveglow_path = 'waveglow/checkpoints/waveglow_50000'\n",
    "\n",
    "def synth_multi(checkpoint_path, waveglow_path, text, savedir):\n",
    "\n",
    "  if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    print(\"Creating directory \" + savedir + \"...\")\n",
    "\n",
    "  hparams = create_hparams()\n",
    "  hparams.sampling_rate = 22050\n",
    "\n",
    "  checkpoint_path = \"outdir/checkpoint_8000\"\n",
    "  model = load_model(hparams)\n",
    "  model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "  _ = model.cuda().eval().half()\n",
    "\n",
    "  waveglow_path = 'waveglow/checkpoints/waveglow_50000'\n",
    "  waveglow = torch.load(waveglow_path)['model']\n",
    "  waveglow.cuda().eval().half()\n",
    "  for k in waveglow.convinv:\n",
    "      k.float()\n",
    "  denoiser = Denoiser(waveglow)\n",
    "\n",
    "  for entry in text:\n",
    "    wav_name = \"_\".join(entry.split(\" \")[:4]).lower() + \".wav\"\n",
    "\n",
    "    epi = epitran.Epitran('eng-Latn', ligatures = True)\n",
    "    if hparams.preprocessing == \"ipa\":\n",
    "      entry = ipa.convert(english_cleaners(entry))\n",
    "      foreign_words = re.findall(r\"[^ ]{0,}\\*\", entry)\n",
    "      for word in foreign_words:\n",
    "        entry = entry.replace(word, epi.transliterate(word[0:len(word)-1]))\n",
    "    if hparams.preprocessing == \"arpabet\":\n",
    "      entry = make_arpabet(entry)\n",
    "\n",
    "    # Text sequencer\n",
    "    if hparams.preprocessing is not None:\n",
    "      sequence = np.array(text_to_sequence(entry, None))[None, :]\n",
    "    else:\n",
    "      sequence = np.array(text_to_sequence(entry, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(\n",
    "      torch.from_numpy(sequence)).cuda().long()\n",
    "\n",
    "    # Synthesis\n",
    "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "    with torch.no_grad():\n",
    "      audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
    "    audio_denoised = denoiser(audio, strength=0.01)[:, 0]\n",
    "\n",
    "    # Save audio\n",
    "    print (\"Saving \" + wav_name)\n",
    "    write(os.path.join(savedir, wav_name), hparams.sampling_rate, audio_denoised[0].data.cpu().numpy())\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument('-t', '--tt2_checkpoint_path', type=str, default=\"tacotron2_statedict.pt\",\n",
    "                        required=False, help='Tacotron2 checkpoint to load')\n",
    "  parser.add_argument('-w', '--waveglow_checkpoint_path', type=str, default=\"waveglow/waveglow_256channels_universal_v5.pt\",\n",
    "                        required=False, help='waveglow checkpoint to load')\n",
    "  parser.add_argument('-f', '--text_file', type=str, \n",
    "                        help='Text file or list to generate audio from.')\n",
    "  parser.add_argument('-o', '--output_directory', type=str, default=\"savedir\",\n",
    "                        required=False, help='Output directory to save to. Defaults to savedir.')\n",
    "  \n",
    "  args = parser.parse_args()\n",
    "\n",
    "  synth_multi(args.tt2_checkpoint_path, args.waveglow_checkpoint_path, args.text_file, args.output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYP5jfsIttSG"
   },
   "outputs": [],
   "source": [
    " cd \"/content/drive/My Drive/ML/tacotron2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRFxgkpMrCEx"
   },
   "outputs": [],
   "source": [
    "!python generate_from_file.py -t \"outdir/checkpoint_20000\" -w \"waveglow/checkpoints/waveglow_130000\" -f \"sample_texts/all-phonemes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VH4PcD5j1y80"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(audio[0].data.cpu().numpy(), rate=hparams.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyID9T8sOkth"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "import epitran\n",
    "import eng_to_ipa as ipa\n",
    "import re\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser\n",
    "from text.cleaners import english_cleaners\n",
    "\n",
    "\n",
    "\n",
    "text = \"Alice opened the door and found that it led into a small passage, not much larger than a rat-hole. \"\n",
    "text_debug = text\n",
    "\n",
    "#epitran preprocessing loop\n",
    "hparams = create_hparams()\n",
    "epi = epitran.Epitran('eng-Latn')\n",
    "if hparams.ipa_preprocessing:\n",
    "  text = ipa.convert(english_cleaners(text))\n",
    "  foreign_words = re.findall(r\"[^ ]{0,}\\*\", text)\n",
    "  for word in foreign_words:\n",
    "    debug_text = text.replace(word, epi.transliterate(word[0:len(word)-1]))\n",
    "\n",
    "def ord_debug_simple(entry):\n",
    "  chars = []\n",
    "  wordlist = []\n",
    "  list = entry.split()\n",
    "  for word in list:\n",
    "    chars = []\n",
    "    chars += word\n",
    "    chars = [ord(char) for char in chars]\n",
    "    wordlist.append(chars)\n",
    "      \n",
    "  return str(wordlist)\n",
    "\n",
    "print(\"english_cleaners: \\t\" + english_cleaners(text_debug))\n",
    "print(\"eng_to_ipa: \\t\\t\" + ipa.convert(english_cleaners(text_debug)))\n",
    "print(\"epitran: \\t\\t\" + epi.transliterate(english_cleaners(text_debug)))\n",
    "print(\"\\n\")\n",
    "print(\"hybrid_mix: \\t\\t\" + debug_text)\n",
    "print(\"hybrid_mix_cleaned: \\t\" + english_cleaners(debug_text))\n",
    "print(\"\\n\")\n",
    "print(\"english_cleaners_ORD: \\t\" + ord_debug_simple(text_debug))\n",
    "print(\"hybrid_mix_ORD: \\t\" + ord_debug_simple(debug_text))\n",
    "print(\"hybrid_cleanded_ORD: \\t\" + ord_debug_simple(english_cleaners(debug_text)))\n",
    "print(\"\\n\")\n",
    "print(\"eng_to_ipa_ORD: \\t\" + ord_debug_simple(ipa.convert(english_cleaners(text_debug))))\n",
    "print(\"epitran_ORD: \\t\\t\" + ord_debug_simple(epi.transliterate(english_cleaners(text_debug))))\n",
    "\n",
    "#text sequencer\n",
    "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.autograd.Variable(\n",
    "    torch.from_numpy(sequence)).cuda().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mxgycMwlRFw"
   },
   "outputs": [],
   "source": [
    "#Tester\n",
    "\n",
    "from hparams import create_hparams\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import re\n",
    "from text import cleaners\n",
    "from text.symbols import symbols\n",
    "\n",
    "import layers\n",
    "from utils import load_wav_to_torch, load_filepaths_and_text, convert_to_ipa, convert_to_arpa\n",
    "from text import text_to_sequence\n",
    "from text import cleaners\n",
    "\n",
    "apath = '../dataset/train.txt'\n",
    "hparams = create_hparams()\n",
    "\n",
    "class TextMelLoader(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        1) loads audio,text pairs\n",
    "        2) normalizes text and converts them to sequences of one-hot vectors\n",
    "        3) computes mel-spectrograms from audio files.\n",
    "    \"\"\"\n",
    "    def __init__(self, audiopaths_and_text, hparams):\n",
    "        self.audiopaths_and_text = load_filepaths_and_text(audiopaths_and_text)[:5]\n",
    "        self.text_cleaners = hparams.text_cleaners\n",
    "        print(self.audiopaths_and_text)\n",
    "        if hparams.preprocessing is not None:\n",
    "            if hparams.preprocessing == 'ipa':\n",
    "                convert_to_ipa(self.audiopaths_and_text)\n",
    "            if hparams.preprocessing == 'arpabet':\n",
    "                convert_to_arpa(self.audiopaths_and_text)\n",
    "            self.text_cleaners = None\n",
    "        print(self.audiopaths_and_text)\n",
    "        self.max_wav_value = hparams.max_wav_value\n",
    "        self.sampling_rate = hparams.sampling_rate\n",
    "        self.load_mel_from_disk = hparams.load_mel_from_disk\n",
    "        self.stft = layers.TacotronSTFT(\n",
    "            hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
    "            hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
    "            hparams.mel_fmax)\n",
    "        random.seed(hparams.seed)\n",
    "        random.shuffle(self.audiopaths_and_text)\n",
    "\n",
    "    def get_mel_text_pair(self, audiopath_and_text):\n",
    "        # separate filename and text\n",
    "        audiopath, text = audiopath_and_text[0], audiopath_and_text[1]\n",
    "        text = self.get_text(text)\n",
    "        mel = self.get_mel(audiopath)\n",
    "        return (text, mel)\n",
    "\n",
    "    def get_mel(self, filename):\n",
    "        if not self.load_mel_from_disk:\n",
    "            audio, sampling_rate = load_wav_to_torch(filename)\n",
    "            if sampling_rate != self.stft.sampling_rate:\n",
    "                raise ValueError(\"{} {} SR doesn't match target {} SR\".format(\n",
    "                    sampling_rate, self.stft.sampling_rate))\n",
    "            audio_norm = audio / self.max_wav_value\n",
    "            audio_norm = audio_norm.unsqueeze(0)\n",
    "            audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
    "            melspec = self.stft.mel_spectrogram(audio_norm)\n",
    "            melspec = torch.squeeze(melspec, 0)\n",
    "        else:\n",
    "            melspec = torch.from_numpy(np.load(filename))\n",
    "            assert melspec.size(0) == self.stft.n_mel_channels, (\n",
    "                'Mel dimension mismatch: given {}, expected {}'.format(\n",
    "                    melspec.size(0), self.stft.n_mel_channels))\n",
    "\n",
    "        return melspec\n",
    "\n",
    "    def get_text(self, text):\n",
    "        text_norm = torch.IntTensor(text_to_sequence(text, self.text_cleaners))\n",
    "        return text_norm\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_mel_text_pair(self.audiopaths_and_text[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audiopaths_and_text)\n",
    "\n",
    "\n",
    "def text_to_sequence(text, cleaner_names):\n",
    "  '''Converts a string of text to a sequence of IDs corresponding to the symbols in the text.\n",
    "\n",
    "    The text can optionally have ARPAbet sequences enclosed in curly braces embedded\n",
    "    in it. For example, \"Turn left on {HH AW1 S S T AH0 N} Street.\"\n",
    "\n",
    "    Args:\n",
    "      text: string to convert to a sequence\n",
    "      cleaner_names: names of the cleaner functions to run the text through\n",
    "\n",
    "    Returns:\n",
    "      List of integers corresponding to the symbols in the text\n",
    "  '''\n",
    "  sequence = []\n",
    "\n",
    "  # Check for curly braces and treat their contents as ARPAbet:\n",
    "  while len(text):\n",
    "    m = _curly_re.match(text)\n",
    "    print(m)\n",
    "    if not m:\n",
    "      sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n",
    "      break\n",
    "    sequence += _symbols_to_sequence(_clean_text(m.group(1), cleaner_names))\n",
    "    sequence += _arpabet_to_sequence(m.group(2))\n",
    "    text = m.group(3)\n",
    "\n",
    "  return sequence\n",
    "\n",
    "def sequence_to_text(sequence):\n",
    "  '''Converts a sequence of IDs back to a string'''\n",
    "  result = ''\n",
    "  for symbol_id in sequence:\n",
    "    if symbol_id in _id_to_symbol:\n",
    "      s = _id_to_symbol[symbol_id]\n",
    "      # Enclose ARPAbet back in curly braces:\n",
    "      if len(s) > 1 and s[0] == '@':\n",
    "        s = '{%s}' % s[1:]\n",
    "      result += s\n",
    "  return result.replace('}{', ' ')\n",
    "\n",
    "\n",
    "def _clean_text(text, cleaner_names):\n",
    "  if cleaner_names is None:\n",
    "    return text\n",
    "  else:\n",
    "    for name in cleaner_names:\n",
    "      cleaner = getattr(cleaners, name)\n",
    "      if not cleaner:\n",
    "        raise Exception('Unknown cleaner: %s' % name)\n",
    "      text = cleaner(text)\n",
    "  return text\n",
    "\n",
    "\n",
    "def _symbols_to_sequence(symbols):\n",
    "  return [_symbol_to_id[s] for s in symbols if _should_keep_symbol(s)]\n",
    "\n",
    "\n",
    "def _arpabet_to_sequence(text):\n",
    "  return _symbols_to_sequence(['@' + s for s in text.split()])\n",
    "\n",
    "\n",
    "def _should_keep_symbol(s):\n",
    "  return s in _symbol_to_id and s is not '_' and s is not '~'\n",
    "\n",
    "\n",
    "text = \"{DH AH0} {B EY1 ZH} {HH Y UW1} {AA1 N} {DH AH0} {W AO1 T ER0 Z} {AH1 V} {DH AH0} {L AA1 K} {IH0 M P R EH1 S T} {AO1 L}, {IH0 N K L UW1 D IH0 NG} {DH AH0} {F R EH1 N CH} {K W IY1 N}, {B IH0 F AO1 R} {SH IY1} {HH ER1 D} {DH AE1 T} {S IH1 M F AH0 N IY0} {AH0 G EH1 N} {JH AH1 S T} {AE1 Z} {Y AH1 NG} {AA1 R TH ER0} {W AA1 N T AH0 D}.\"\n",
    "# Mappings from symbol to numeric ID and vice versa:\n",
    "_symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
    "_id_to_symbol = {i: s for i, s in enumerate(symbols)}\n",
    "\n",
    "# Regular expression matching text enclosed in curly braces:\n",
    "_curly_re = re.compile(r'(.*?)\\{(.+?)\\}(.*)')\n",
    "\n",
    "seq = text_to_sequence(text, None)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wF6rvm9etBRo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "tacotron2_git.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
